{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import sklearn\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset/train.csv')\n",
    "# data = data.drop('id', 1)\n",
    "\n",
    "# split into train and test\n",
    "train, test = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation:\n",
    "* Exploration (EDA) & Visualizaiton\n",
    "* Cleaning\n",
    "* Wrangling & Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Exploration (EDA) & Visualizaiton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General info about data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_variables = ['cleaning_fee', 'host_has_profile_pic', 'host_identity_verified', 'instant_bookable']\n",
    "\n",
    "categorical_variables = ['property_type', 'room_type', 'bed_type', 'cancellation_policy', 'city',\n",
    "                         'neighbourhood', 'amenities']\n",
    "\n",
    "numeric_variables = ['log_price', 'accommodates', 'bathrooms', 'host_response_rate', 'latitude', 'longitude',\n",
    "                     'number_of_reviews', 'review_scores_rating', 'bedrooms', 'beds']  \n",
    "\n",
    "column_to_drop = ['id', 'name', 'thumbnail_url', 'zipcode', 'description', 'first_review',\n",
    "                  'host_since', 'last_review']\n",
    "\n",
    "columns = {'binary_variables': binary_variables, 'categorical_variables': categorical_variables,\n",
    "           'numeric_variables': numeric_variables, 'column_to_drop': column_to_drop, 'binned_variables': []}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize a Matplotlib figures grid\n",
    "fig, axes = plt.subplots(5, 2,figsize=(24,24))\n",
    "\n",
    "#generate a histogram using Pandas, for each numeric variable\n",
    "# TODO bin host_response_rate\n",
    "for i in range(5):\n",
    "    for j in range(2):\n",
    "        var = numeric_variables[i*2+j]\n",
    "        train[var].hist(ax=axes[i,j])\n",
    "        axes[i,j].set_title(var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate a figures grid:\n",
    "fig, axes = plt.subplots(4,2,figsize=(16,16))\n",
    "fig.subplots_adjust(hspace=0.8)\n",
    "\n",
    "#we will create a histogram for each categorical attribute\n",
    "n=len(categorical_variables)\n",
    "num_rows = 2\n",
    "max_bars = 8\n",
    "\n",
    "for i,variable in enumerate(categorical_variables):\n",
    "    #calculate the current place on the grid\n",
    "    r=int(i/num_rows)\n",
    "    c=i%num_rows\n",
    "    \n",
    "    #create the \"value counts\" for the first <max_bars> categories:\n",
    "    u=min(train[variable].nunique(),max_bars)\n",
    "    vc = train[variable].value_counts()[:u]\n",
    "    \n",
    "    # plot a bar chart using Pandas\n",
    "    vc.plot(kind='bar',ax=axes[r,c],title=variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate a figures grid:\n",
    "fig, axes = plt.subplots(2,2,figsize=(16,16))\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "\n",
    "#we will create a histogram for each categorical attribute\n",
    "n=len(binary_variables)\n",
    "num_rows = 2\n",
    "max_bars = 8\n",
    "\n",
    "for i,variable in enumerate(binary_variables):\n",
    "    #calculate the current place on the grid\n",
    "    r=int(i/num_rows)\n",
    "    c=i%num_rows\n",
    "    \n",
    "    #create the \"value counts\" for the first <max_bars> categories:\n",
    "    u=min(train[variable].nunique(),max_bars)\n",
    "    vc = train[variable].value_counts()[:u]\n",
    "    \n",
    "    # plot a bar chart using Pandas\n",
    "    vc.plot(kind='bar',ax=axes[r,c],title=variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviews may affect price, (e.g. positive reviews may add 'prestige')\n",
    "years_of_last_review = pd.DataFrame({\n",
    "    'year of last review':pd.to_datetime(train['last_review'], format='%Y-%m-%d', errors='coerce').dt.year.fillna(0),\n",
    "    'log_price': train['log_price']\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "sns.countplot(x=\"year of last review\", data=years_of_last_review)\n",
    "plt.title('Row count')\n",
    "plt.show()\n",
    "\n",
    "# plt.figure(figsize=(12,8))\n",
    "# sns.boxplot(data=years_of_last_review,orient='v', x = 'year of last review', y = 'log_price')\n",
    "# plt.title('Years of last review and price')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "sns.heatmap(train.corr(method='spearman'), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nan value counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count nan values\n",
    "len(train) - train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(train.isnull(),yticklabels=False,cbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for var in binary_variables:\n",
    "    print(var, len(train[var].unique()))\n",
    "\n",
    "for var in categorical_variables:\n",
    "    print(var, len(train[var].unique()))\n",
    "\n",
    "for var in numeric_variables:\n",
    "    print(var, len(train[var].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotGrid(data, columnFilter, plotFunc, rows, columns):\n",
    "    data = data.copy()\n",
    "    data['host_response_rate'] = data['host_response_rate'].str.rstrip('%').astype('float') / 100.0\n",
    "\n",
    "    fig, axes = plt.subplots(rows, columns,figsize=(columns * 8,rows * 8))\n",
    "    fig.subplots_adjust(hspace=0.5)\n",
    "\n",
    "    for i, var in enumerate(columnFilter):\n",
    "        r=int(i/columns)\n",
    "        c=i%columns\n",
    "        \n",
    "        plotFunc(data[var], ax=axes[r,c])\n",
    "        axes[r,c].set_title(var)\n",
    "\n",
    "# A kernel density estimate (KDE) plot is a method for visualizing the distribution of observations in\n",
    "# a dataset, analagous to a histogram. KDE represents the data using a continuous probability density\n",
    "# curve in one or more dimensions.\n",
    "plotGrid(train, numeric_variables, sns.kdeplot, 2, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Price by classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, figsize=(20, 24))\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "catVals = categorical_variables.copy()\n",
    "\n",
    "# Dont show graphs for those classes since they aren't good before data cleaning\n",
    "if 'amenities' in catVals:\n",
    "    catVals.remove('amenities')\n",
    "if 'neighbourhood' in catVals:\n",
    "    catVals.remove('neighbourhood')\n",
    "\n",
    "# convert log_price to price\n",
    "train['price'] = list(map(lambda x: np.e ** x,train.log_price))\n",
    "for i, var in enumerate(catVals):\n",
    "    r = i % 3\n",
    "    c = int(i / 3)\n",
    "    train.groupby(var)['price'].mean().plot.bar(ax=axes[r,c], title='Mean price by ' + var)\n",
    "\n",
    "del train['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "\n",
    "number_of_reviews_low = train[train['number_of_reviews'] <=50]\n",
    "number_of_reviews_high = train[train['number_of_reviews'] > 50]\n",
    "\n",
    "sns.distplot(number_of_reviews_low.log_price, bins = 25, kde = True, label = \"#reviews<=50\",ax=ax)\n",
    "sns.distplot(number_of_reviews_high.log_price, bins = 25, kde = True, label = \"#reviews>50\",ax=ax)\n",
    "\n",
    "#Don't forget to make titles for the figure and axes\n",
    "plt.title('Class-wise Histogram of log price')\n",
    "plt.xlabel('log_price')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "\n",
    "reviewScoreLow = train[train['review_scores_rating'] <= 50]\n",
    "reviewScoreHigh = train[train['review_scores_rating'] > 50]\n",
    "\n",
    "sns.distplot(reviewScoreLow.log_price, bins = 25, kde = True, label = \"review score <=50\",ax=ax)\n",
    "sns.distplot(reviewScoreHigh.log_price, bins = 25, kde = True, label = \"review score >50\",ax=ax)\n",
    "\n",
    "#Don't forget to make titles for the figure and axes\n",
    "plt.title('Class-wise Histogram of log price')\n",
    "plt.xlabel('log_price')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "\n",
    "reviewScoreLow = train[train['instant_bookable'] == 't']\n",
    "reviewScoreHigh = train[train['instant_bookable'] == 'f']\n",
    "\n",
    "sns.distplot(reviewScoreLow.log_price, bins = 25, kde = True, label = \"Instant bookable\",ax=ax)\n",
    "sns.distplot(reviewScoreHigh.log_price, bins = 25, kde = True, label = \"Not instant bookable\",ax=ax)\n",
    "\n",
    "#Don't forget to make titles for the figure and axes\n",
    "plt.title('Class-wise Histogram of log price')\n",
    "plt.xlabel('log_price')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "\n",
    "reviewScoreLow = train[train['host_identity_verified'] == 't']\n",
    "reviewScoreHigh = train[train['host_identity_verified'] == 'f']\n",
    "\n",
    "sns.distplot(reviewScoreLow.log_price, bins = 25, kde = True, label = \"Host identity verified\",ax=ax)\n",
    "sns.distplot(reviewScoreHigh.log_price, bins = 25, kde = True, label = \"Host identity not verified\",ax=ax)\n",
    "\n",
    "#Don't forget to make titles for the figure and axes\n",
    "plt.title('Class-wise Histogram of log price')\n",
    "plt.xlabel('log_price')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QQ Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the data values fall along a roughly straight line at a 45-degree angle,\n",
    "# then the data is normally distributed. \n",
    "fig = sm.qqplot(train['log_price'], line='45')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Unnecessary Column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in columns['column_to_drop']:\n",
    "    train = train.drop(column, axis=1)\n",
    "    test = test.drop(column, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type Conversion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boolean Variables hendling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in columns['binary_variables']:\n",
    "    train[column] = train[column].apply(lambda x: True if x == 'TRUE' or x == 't' else False)\n",
    "    test[column] = test[column].apply(lambda x: True if x == 'TRUE' or x == 't' else False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Numeric Variables to Float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['host_response_rate'] = train['host_response_rate'].str.rstrip('%').astype('float') / 100.0\n",
    "test['host_response_rate'] = test['host_response_rate'].str.rstrip('%').astype('float') / 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in columns['numeric_variables']:\n",
    "    train[column] = train[column].astype(float)\n",
    "    test[column] = test[column].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impute Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_columns = []\n",
    "for column in columns['binary_variables'] + columns['categorical_variables'] + columns['numeric_variables']:\n",
    "    if train[column].isnull().sum():\n",
    "        null_columns.append(column)\n",
    "    if test[column].isnull().sum():\n",
    "        null_columns.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_most_frequent_values = train.copy()\n",
    "test_with_most_frequent_values = test.copy()\n",
    "for column in null_columns:\n",
    "    val = train_with_most_frequent_values[column].value_counts().index[0]\n",
    "    train_with_most_frequent_values[column] = train_with_most_frequent_values[column].fillna(val)\n",
    "    test_with_most_frequent_values[column] = test_with_most_frequent_values[column].fillna(val)\n",
    "\n",
    "train = train_with_most_frequent_values\n",
    "test = test_with_most_frequent_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reset Indexes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reset_index()\n",
    "test = test.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Wrangling & Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_amenities(data, columns_dict):\n",
    "    chars_to_remove = '\"{}'\n",
    "    amenities_set = set()\n",
    "    for line in data['amenities']:\n",
    "        amenities = line.split(',')\n",
    "        for obj in amenities:\n",
    "            for char in chars_to_remove:\n",
    "                obj = obj.replace(char, \"\")\n",
    "            if \"translation missing\" not in obj and obj != '':\n",
    "                amenities_set.add(obj)\n",
    "    for amenity in amenities_set:\n",
    "        columns_dict['binary_variables'].append(amenity)\n",
    "    return list(amenities_set)\n",
    "\n",
    "\n",
    "def create_amenities_array(amenities_list, data):\n",
    "    amenities_array = []\n",
    "    for index, row in data.iterrows():\n",
    "        array = np.zeros(shape=(len(amenities_list)))\n",
    "        row_amen = data['amenities'][index].split(',')\n",
    "        for amen in row_amen:\n",
    "            item = amen.replace('\"', '').replace('}', '').replace('{', '')\n",
    "            if item in amenities_list:\n",
    "                res = amenities_list.index(item)\n",
    "                array[res] = 1\n",
    "        amenities_array.append(array.tolist())\n",
    "\n",
    "    amenities_df = pd.DataFrame(amenities_array, columns=amenities_list)\n",
    "    return amenities_df\n",
    "\n",
    "\n",
    "# converting amenities column to binary columns and updating columns_dict\n",
    "def create_amenities_cols(data, amenities_set):\n",
    "    amenities_array = create_amenities_array(amenities_set, data)\n",
    "\n",
    "    data = data.drop(['amenities'], axis=1)\n",
    "    data = pd.concat([data, amenities_array], axis=1)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amenities_list = collect_amenities(train, columns)\n",
    "train = create_amenities_cols(train, amenities_list)\n",
    "test = create_amenities_cols(test, amenities_list)\n",
    "columns['categorical_variables'].remove('amenities')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_neighbourhoods = train['neighbourhood'].value_counts().head(50).keys()\n",
    "for index, row in train.iterrows():\n",
    "    if row['neighbourhood'] not in top_neighbourhoods:\n",
    "        train.at[index,'neighbourhood'] = 'other'\n",
    "for index, row in test.iterrows():\n",
    "    if row['neighbourhood'] not in top_neighbourhoods:\n",
    "        test.at[index,'neighbourhood'] = 'other'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one hot encoding gor catagorial varaiables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we leave the target feature as is\n",
    "oh_train = train['log_price']\n",
    "oh_test = test['log_price']\n",
    "\n",
    "# now adding the one hot encoded data\n",
    "for variable in columns['binned_variables']+columns['categorical_variables']:\n",
    "    onehot_train_col = pd.get_dummies(train[variable], prefix=variable)\n",
    "    oh_train = pd.concat([oh_train, onehot_train_col], axis=1)\n",
    "\n",
    "    onehot_test_col = pd.get_dummies(test[variable], prefix=variable)\n",
    "    oh_test = pd.concat([oh_test, onehot_test_col], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### concatenating binary varaiables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in columns['binary_variables']:\n",
    "    train[col] = train[col].replace(True, 1)\n",
    "    train[col] =train[col].replace(False, 0)\n",
    "    oh_train = pd.concat([oh_train, train[col]], axis=1)\n",
    "\n",
    "    test[col] = test[col].replace(True, 1)\n",
    "    test[col] = test[col].replace(False, 0)\n",
    "    oh_test = pd.concat([oh_test, test[col]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### concatenating numeric varaiables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in columns['numeric_variables']:\n",
    "    if col != 'log_price':\n",
    "        oh_train = pd.concat([oh_train, train[col]], axis=1)\n",
    "\n",
    "        oh_test = pd.concat([oh_test, test[col]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### equalize cloumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_to_test = list(set(oh_train.columns) - set(oh_test.columns))\n",
    "add_to_train = list(set(oh_test.columns) - set(oh_train.columns))\n",
    "for col in add_to_train:\n",
    "    oh_train[col] = 0\n",
    "for col in add_to_test:\n",
    "    oh_test[col] = 0\n",
    "\n",
    "oh_test = oh_test[oh_train.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train Model: Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression = linear_model.LinearRegression()\n",
    "# separate labels from data=\n",
    "train_class = oh_train['log_price']\n",
    "oh_train_data = oh_train.drop('log_price', axis=1)\n",
    "# train the model:\n",
    "linear_regression.fit(oh_train_data, train_class)\n",
    "print(linear_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_evaluation(model, train_x, train_y, test_x, test_y, prediction_test):\n",
    "    #show_metrics(prediction_test, prediction_train, test_y, train_y)\n",
    "    r2 = r2_score(test_y, prediction_test)\n",
    "    print('r2 score:', r2)\n",
    "\n",
    "    print(\"Mean Absolute Perc Error (Σ(|y-pred|/y)/n):\",\n",
    "          \"{:,.3f}\".format(mean_absolute_percentage_error(test_y, prediction_test)))\n",
    "    print(\"Mean Absolute Error (Σ|y-pred|/n):\", \"{:,.3f}\".format(mean_absolute_error(test_y, prediction_test)))\n",
    "    print(\"Root Mean Squared Error (sqrt(Σ(y-pred)^2/n)):\", \"{:,.3f}\".\n",
    "          format(np.sqrt(mean_squared_error(test_y, prediction_test))))\n",
    "\n",
    "    ## residuals\n",
    "    residuals = test_y - prediction_test\n",
    "    max_error = max(prediction_test) if abs(max(residuals)) > abs(min(residuals)) else min(residuals)\n",
    "    max_idx = list(residuals).index(max(residuals)) if abs(max(residuals)) > abs(min(residuals)) else list(\n",
    "        residuals).index(min(residuals))\n",
    "    max_true, max_pred = test_y[max_idx], prediction_test[max_idx]\n",
    "    print(\"Max Error:\", \"{:,.0f}\".format(max_error))\n",
    "\n",
    "    # fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    sns.scatterplot(x=prediction_test, y=test_y)\n",
    "    sns.lineplot(x=prediction_test, y=prediction_test, color='black')\n",
    "    plt.title('true values against the predicted values')\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(16, 5))\n",
    "    sns.scatterplot(x=prediction_test, y=residuals, ax=ax[0])\n",
    "    sns.lineplot(x=prediction_test, y=0, ax=ax[0], color='black')\n",
    "    ax[0].set_title(\"Residuals (Abs)\")\n",
    "    sns.scatterplot(x=prediction_test, y=residuals / test_y, ax=ax[1])\n",
    "    sns.lineplot(x=prediction_test, y=0, ax=ax[1], color='black')\n",
    "    ax[1].set_title(\"Residuals (%)\")\n",
    "    plt.show()\n",
    "\n",
    "    rel_res = residuals / test_y\n",
    "\n",
    "    rel_res = abs(rel_res)\n",
    "    print(len(rel_res[rel_res < 0.05]) / len(rel_res))\n",
    "    print(len(rel_res[rel_res > 0.2]) / len(rel_res))\n",
    "\n",
    "    model_analysis(model, train_x)\n",
    "    # todo - shap\n",
    "    # shap_cal(model, train_x, test_x, test_y, rel_res, prediction_test, residuals)\n",
    "\n",
    "    # https://www.kaggle.com/code/mohamedmokhtar7/airbnb-eda-and-regression#kln-346\n",
    "    sns.regplot(x=test_y, y=prediction_test, fit_reg=False)\n",
    "    plt.title('Prediction and real')\n",
    "    plt.show()\n",
    "\n",
    "    sns.distplot(test_y - prediction_test, bins=50)\n",
    "    plt.title('Error variance')\n",
    "    plt.show()\n",
    "\n",
    "def model_analysis(model, train_x):\n",
    "    print(\"Model coefficients:\\n\")\n",
    "    for i in range(len(train_x.columns)):\n",
    "        print(train_x.columns[i], \"=\", model.coef_[i].round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = oh_train['log_price'].values\n",
    "train_x = oh_train.drop('log_price', axis=1)\n",
    "test_y = oh_test['log_price'].values\n",
    "test_x = oh_test.drop('log_price', axis=1)\n",
    "\n",
    "prediction_test = linear_regression.predict(test_x)\n",
    "prediction_train = linear_regression.predict(train_x)\n",
    "\n",
    "plot_evaluation(\n",
    "    model=linear_regression,\n",
    "    train_x=train_x,\n",
    "    train_y=train_y,\n",
    "    test_x=test_x,\n",
    "    test_y=test_y,\n",
    "    prediction_test=prediction_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
